{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import audiolabel as al"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix file to reflect hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'vowels'\n",
    "segs = 20\n",
    "\n",
    "df = pd.read_csv('VS/' + folder + '/output-' + str(segs) + '.txt', sep = '\\t')\n",
    "\n",
    "# Get rid of unnamed columns\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "\n",
    "# Get duration\n",
    "df['dur'] = df['seg_End'] - df['seg_Start']\n",
    "\n",
    "# Sort df by filename THEN seg start\n",
    "df = df.sort_values(by = ['Filename', 'seg_Start']).reset_index(drop = True)\n",
    "\n",
    "# Get truth values for whether it is sequence name or not--if it is, we need to change the hierachy\n",
    "is_seq = df.Label.str.islower()\n",
    "\n",
    "# Collect sequences\n",
    "seq = []\n",
    "\n",
    "# Make unique ID for each sequence too\n",
    "seq_id_count = 0\n",
    "seq_id = []\n",
    "\n",
    "for i in range(len(is_seq)):\n",
    "    val = is_seq[i]\n",
    "    \n",
    "    # If not sequence, copy\n",
    "    if val == True:\n",
    "        j = i\n",
    "        seq_id_count += 1\n",
    "    \n",
    "    seq.append(df.Label[j])\n",
    "    seq_id.append(seq_id_count)\n",
    "\n",
    "# Add to data frame\n",
    "df['seq'] = seq\n",
    "df['seq_id'] = seq_id\n",
    "\n",
    "# Get rid of sequence labels\n",
    "df = df[df['Label'] != df['seq']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mark as V1, C, or V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index\n",
    "df = df.reset_index(drop = True)\n",
    "\n",
    "def map_seg(seg, folder):\n",
    "    '''\n",
    "    Maps segment to V1, C, or V2\n",
    "    '''\n",
    "    # VCV sequences\n",
    "    if folder in ['metathesis', 'vowels_double_u-i']:\n",
    "    \n",
    "        to_seg = {0: 'V1',\n",
    "                  1: 'C',\n",
    "                  2: 'V2'}\n",
    "        \n",
    "        return(to_seg[seg % 3])\n",
    "\n",
    "    # CV sequences\n",
    "    elif folder in ['vowels']:\n",
    "    \n",
    "        to_seg = {0: 'C',\n",
    "                  1: 'V'}\n",
    "        \n",
    "        return(to_seg[seg % 2])\n",
    "\n",
    "df['part'] = df.apply(lambda x: map_seg(x.name, folder), axis = 1)\n",
    "\n",
    "### Make before and after series\n",
    "before = []\n",
    "after = []\n",
    "word = []\n",
    "sentence = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    tg = al.LabelManager(from_file='./VS/' + folder + '/files_realigned/' + df['Filename'][i].split('.')[0] + '.TextGrid', from_type='praat')\n",
    "\n",
    "    #print(df['Filename'][i])\n",
    "\n",
    "    # Round and add .0001 to make sure you are IN the interval\n",
    "    seg_st = round(df.at[i, 'seg_Start']/1000, 4) + .0001\n",
    "\n",
    "    #print(seg_st)\n",
    "\n",
    "    #print(tg.tier('transcription - phones'))\n",
    "    #print(tg.tier('transcription - phones').label_at(seg_st))\n",
    "    word.append(tg.tier('transcription - words').label_at(seg_st).text)\n",
    "    sentence.append(' '.join(' '.join([label.text for label in tg.tier('transcription - words')]).split()))\n",
    "    before.append(tg.tier('transcription - phones').prev(tg.tier('transcription - phones').label_at(seg_st)).text)\n",
    "    after.append(tg.tier('transcription - phones').next(tg.tier('transcription - phones').label_at(seg_st)).text)\n",
    "\n",
    "df['before'] = before\n",
    "df['after'] = after\n",
    "df['word'] = word\n",
    "df['sentence'] = sentence\n",
    "\n",
    "# Add column for adjusted V1\n",
    "issues = pd.read_csv('VS/' + folder + '/issues.csv')\n",
    "\n",
    "def get_issue(row):\n",
    "    '''\n",
    "    Look up issues in issues.csv file\n",
    "    '''\n",
    "    file = row.Filename[:-4]\n",
    "    #return(' '.join(issues.loc[issues['file'] == file].issues.values))\n",
    "    return(' '.join(issues.loc[issues['audio'] == file].issues.values))\n",
    "    \n",
    "df['issue'] = df.apply(lambda x: get_issue(x), axis = 1)\n",
    "\n",
    "# Now fix V1 and V2 values based on issues\n",
    "df['dur_mod'] = df.apply(lambda x: 0 if x.issue in [x.part + ' absent', x.part + ' absent?'] else x.dur, axis = 1)\n",
    "\n",
    "# Final df\n",
    "cols = ['Filename', 'seq', 'seq_id', 'Label', 'part', 'word', 'sentence', 'before', 'after', 'dur_mod']\n",
    "df = df[cols + [c for c in df if c not in cols]]\n",
    "\n",
    "df.to_csv('VS/' + folder + '/output-' + str(segs) + '_rev.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix tier names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import glob\n",
    "# import os\n",
    "\n",
    "# files = [f for f in sorted(glob.glob('./VS/files_realigned/*.TextGrid', recursive = True))]\n",
    "\n",
    "# for f in files:\n",
    "#     # BASENAME: \n",
    "#     newf = './VS/files_fixedtiernames/' + os.path.basename(f)\n",
    "    \n",
    "#     # Read in the TextGrid to fix the tier names\n",
    "#     with open(f, 'r') as r:\n",
    "#         with open(newf, 'w') as w:\n",
    "#             # Make counter\n",
    "#             i = 1\n",
    "#             for line in r:\n",
    "#                 # If tier name doesn't exist\n",
    "#                 if 'name = \"\"' in line:\n",
    "#                     # First tier will be target seq\n",
    "#                     if i == 1:\n",
    "\n",
    "#                         line = line.replace('\"\"', '\"targetseq\"')\n",
    "#                         # Add to make sure we replace with target phone\n",
    "#                         i += 1\n",
    "#                     elif i == 2: \n",
    "#                         line = line.replace('\"\"', '\"targetphone\"')\n",
    "#                         i += 1\n",
    "#                 w.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in fixed file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./VS/' + folder + '/output-' + str(segs) + '_rev.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turn from wide data to long\n",
    "stubnames are the timepoints we want\n",
    "i are the ID names we want to subdivide by (speaker)\n",
    "j is the timepoint, since it is the suffix of the stubnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure we are working with\n",
    "# pF1_means = first formant\n",
    "# pF2_means = second formant\n",
    "premeasure = 'pF2'\n",
    "measure = premeasure + '_means'\n",
    "\n",
    "# Concatenate \n",
    "cols_a = df.loc[:, ['Filename', 'seq', 'seq_id', 'Label', 'word', 'sentence', 'before', 'after', 'part', 'issue', 'dur_mod', 'dur'] ]\n",
    "cols_b = df.loc[:, [measure + \"{:03}\".format(i+1) for i in range(segs)] ]\n",
    "\n",
    "wide_df = pd.concat([cols_a, cols_b], axis=1)\n",
    "\n",
    "# Get V1 duration\n",
    "# Get V2 max - min F2\n",
    "\n",
    "wide_df['C_dur'] = wide_df.seq_id.apply(lambda x: wide_df.loc[(wide_df['seq_id'] == x) & (wide_df['part'] == 'C')].dur_mod.values[0])\n",
    "\n",
    "if folder == 'vowels':\n",
    "    wide_df['V_dur'] = wide_df.seq_id.apply(lambda x: wide_df.loc[(wide_df['seq_id'] == x) & (wide_df['part'] == 'V')].dur_mod.values[0])\n",
    "\n",
    "    wide_df['V_max' + premeasure] = wide_df.seq_id.apply(lambda x: wide_df.loc[(wide_df['seq_id'] == x) & (wide_df['part'] == 'V')][[measure + \"{:03}\".format(i+1) for i in range(segs)]].max(axis = 1).values[0])\n",
    "    wide_df['V_max' + premeasure + '_tpt'] = wide_df.seq_id.apply(lambda x: pd.to_numeric(wide_df.loc[(wide_df['seq_id'] == x) & (wide_df['part'] == 'V')][[measure + \"{:03}\".format(i+1) for i in range(segs)]].idxmax(axis=1).values[0][-3:]))\n",
    "    wide_df['V_min' + premeasure] = wide_df.seq_id.apply(lambda x: wide_df.loc[(wide_df['seq_id'] == x) & (wide_df['part'] == 'V')][[measure + \"{:03}\".format(i+1) for i in range(segs)]].min(axis = 1).values[0])\n",
    "    wide_df['V_min' + premeasure + '_tpt'] = wide_df.seq_id.apply(lambda x: pd.to_numeric(wide_df.loc[(wide_df['seq_id'] == x) & (wide_df['part'] == 'V')][[measure + \"{:03}\".format(i+1) for i in range(segs)]].idxmin(axis=1).values[0][-3:]))\n",
    "\n",
    "    wide_df['V_' + premeasure + 'diff'] = wide_df['V_max' + premeasure] - wide_df['V_min' + premeasure]\n",
    "    \n",
    "else:\n",
    "    wide_df['V1_dur'] = wide_df.seq_id.apply(lambda x: wide_df.loc[(wide_df['seq_id'] == x) & (wide_df['part'] == 'V1')].dur_mod.values[0])\n",
    "    wide_df['V2_dur'] = wide_df.seq_id.apply(lambda x: wide_df.loc[(wide_df['seq_id'] == x) & (wide_df['part'] == 'V2')].dur_mod.values[0])\n",
    "\n",
    "    wide_df['V2_max' + premeasure] = wide_df.seq_id.apply(lambda x: wide_df.loc[(wide_df['seq_id'] == x) & (wide_df['part'] == 'V2')][[measure + \"{:03}\".format(i+1) for i in range(segs)]].max(axis = 1).values[0])\n",
    "    wide_df['V2_max' + premeasure + '_tpt'] = wide_df.seq_id.apply(lambda x: pd.to_numeric(wide_df.loc[(wide_df['seq_id'] == x) & (wide_df['part'] == 'V2')][[measure + \"{:03}\".format(i+1) for i in range(segs)]].idxmax(axis=1).values[0][-3:]))\n",
    "    wide_df['V2_min' + premeasure] = wide_df.seq_id.apply(lambda x: wide_df.loc[(wide_df['seq_id'] == x) & (wide_df['part'] == 'V2')][[measure + \"{:03}\".format(i+1) for i in range(segs)]].min(axis = 1).values[0])\n",
    "    wide_df['V2_min' + premeasure + '_tpt'] = wide_df.seq_id.apply(lambda x: pd.to_numeric(wide_df.loc[(wide_df['seq_id'] == x) & (wide_df['part'] == 'V2')][[measure + \"{:03}\".format(i+1) for i in range(segs)]].idxmin(axis=1).values[0][-3:]))\n",
    "\n",
    "    wide_df['V2_' + premeasure + 'diff'] = wide_df['V2_max' + premeasure] - wide_df['V2_min' + premeasure]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now transform into long dataset\n",
    "if folder == 'vowels':\n",
    "    long_df = pd.melt(wide_df, id_vars=['Filename', 'seq', 'seq_id', 'part', 'issue', 'dur_mod', 'dur', 'Label', 'word', 'sentence', 'before', 'after', 'V_dur', 'C_dur', 'V_max' + premeasure, 'V_max' + premeasure + '_tpt', 'V_min' + premeasure, 'V_min' + premeasure + '_tpt', 'V_' + premeasure + 'diff'], var_name='timepoint', value_name=measure)\n",
    "\n",
    "else:\n",
    "    long_df = pd.melt(wide_df, id_vars=['Filename', 'seq', 'seq_id', 'part', 'issue', 'dur_mod', 'dur', 'Label', 'word', 'sentence', 'before', 'after', 'V1_dur', 'C_dur', 'V2_dur', 'V2_max' + premeasure, 'V2_max' + premeasure + '_tpt', 'V2_min' + premeasure, 'V2_min' + premeasure + '_tpt', 'V2_' + premeasure + 'diff'], var_name='timepoint', value_name=measure)\n",
    "\n",
    "# z-score normalized by speaker\n",
    "#zscore = lambda x: (x - x.mean()) / x.std()\n",
    "#long_df.insert(len(long_df.columns), 'z-score', long_df.groupby(['sp'])[measure].transform(zscore))\n",
    "\n",
    "# TURN LAST THREE DIGITS INTO INTEGER\n",
    "long_df['timepoint'] = pd.to_numeric(long_df[\"timepoint\"].str[-3:]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "cons = ['p', 'f', 'x', 'k']\n",
    "\n",
    "if folder == 'vowels':\n",
    "    \n",
    "    long_df['C'] = long_df.seq.str[0]\n",
    "    long_df['V'] = long_df.seq.str[1:]\n",
    "    long_df['V_qual'] = long_df.V.str[0]\n",
    "\n",
    "else:\n",
    "\n",
    "    def get_vc(seq):\n",
    "        for c in cons:\n",
    "            if c in seq:\n",
    "                surr_v = seq.split(c)\n",
    "\n",
    "                return(surr_v[0], c, surr_v[1])\n",
    "            else:\n",
    "                next\n",
    "\n",
    "    # Add V1, C, and V2\n",
    "    vcv = long_df.seq.apply(get_vc)\n",
    "\n",
    "    new_col_list = ['V1', 'C', 'V2']\n",
    "    for n, col in enumerate(new_col_list):\n",
    "        long_df[col] = vcv.apply(lambda x: x[n])\n",
    "\n",
    "    long_df['V1_qual'] = long_df.V1.str[0]\n",
    "    long_df['V2_qual'] = long_df.V2.str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df.to_csv('VS/' + folder + '/output-' + str(segs) + '_long_' + premeasure + '.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
